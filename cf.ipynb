{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5679283f",
   "metadata": {},
   "source": [
    "# Exploring Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df0f1d",
   "metadata": {},
   "source": [
    "### By developing a movie recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df338b",
   "metadata": {},
   "source": [
    "### Movie Dataset\n",
    "Dataset source - http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8aca1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8239e5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "0            1        1     4.0   964982703\n",
       "1            1        3     4.0   964981247\n",
       "2            1        6     4.0   964982224\n",
       "3            1       47     5.0   964983815\n",
       "4            1       50     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb6656",
   "metadata": {},
   "source": [
    "### Splitting data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "453bfbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "msk = np.random.rand(len(ratings)) < 0.8\n",
    "train = ratings[msk].copy()\n",
    "val = ratings[~msk].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43fb417",
   "metadata": {},
   "source": [
    "### Encode data\n",
    "Encode data with continous user and movie ids, if train is passed to the function call, we encode df with the same encoding as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90b97e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_col(col, train_col=None):\n",
    "  # use training col if available\n",
    "  if train_col is not None:\n",
    "    uniq = train_col.unique()\n",
    "  else:\n",
    "    uniq = col.unique()\n",
    "\n",
    "  # mapping value to index\n",
    "  name2idx = {}\n",
    "  for index, val in enumerate(uniq):\n",
    "    name2idx[val] = index\n",
    "  arr = []\n",
    "  for x in col:\n",
    "    # uknown ids get encoded as -1\n",
    "    arr.append(name2idx.get(x, -1))\n",
    "  arr = np.array(arr)\n",
    "  return name2idx, arr, len(uniq) # understanding mapping, encoded array, number of unique categories\n",
    "\n",
    "def encode_data(df, train=None):\n",
    "  df = df.copy()\n",
    "  for col_name in [\"userId\", \"movieId\"]:\n",
    "    train_col = None\n",
    "    if train is not None:\n",
    "      train_col = train[col_name]\n",
    "    _, col, _ = proc_col(df[col_name], train_col)\n",
    "    df[col_name] = col\n",
    "\n",
    "    # removing the unknowns (value of -1)\n",
    "    df = df[df[col_name] >= 0]\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a0af1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = encode_data(train)\n",
    "df_val = encode_data(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c943845",
   "metadata": {},
   "source": [
    "### Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "85ca8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7e4b593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating embedding layer (matrix) with 10 rows and 3 columns\n",
    "# first filled with random numbers, so model can learn later during training\n",
    "embed = nn.Embedding(10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ffa62",
   "metadata": {},
   "source": [
    "### Matrix Factorization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2df4bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "  def __init__(self, num_users, num_items, emb_size=100):\n",
    "    super(MF, self).__init__()\n",
    "    # lookup table for all users\n",
    "    self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "\n",
    "    # lookup table for all items\n",
    "    self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "\n",
    "    # initialize each randomly\n",
    "    self.user_emb.weight.data.uniform_(0, 0.05)\n",
    "    self.item_emb.weight.data.uniform_(0, 0.05)\n",
    "      \n",
    "  def forward(self, u, v):\n",
    "    # replace each row with the embedding layer row\n",
    "    u = self.user_emb(u)\n",
    "    v = self.item_emb(v)\n",
    "\n",
    "    # dot product of u and v\n",
    "    return (u*v).sum(1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c02f7",
   "metadata": {},
   "source": [
    "### Training the MF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7731ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num users: 610\n",
      "num items: 8998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_users = len(df_train.userId.unique())\n",
    "num_items = len(df_train.movieId.unique())\n",
    "print(\"num users:\", num_users)\n",
    "print(\"num items:\", num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b15789bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the new matrix factorization model\n",
    "model = MF(num_users, num_items, emb_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "71789eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how good the current model is without changing anything\n",
    "def test_loss(model, unsqueeze=False):\n",
    "  model.eval()\n",
    "  users = torch.LongTensor(df_val['userId'].values)\n",
    "  items = torch.LongTensor(df_val['movieId'].values)\n",
    "  ratings = torch.FloatTensor(df_val['rating'].values)\n",
    "  if unsqueeze:\n",
    "    ratings = ratings.unsqueeze(1)\n",
    "  y_hat = model(users, items)\n",
    "  loss = F.mse_loss(y_hat, ratings)\n",
    "  print(f\"test loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "86518a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr: learning rate for Adam (speed of learning)\n",
    "# wd: weight decay (L2 regularization) applied by Adam to all model params (your embeddings).\n",
    "# unsqueeze: whether to reshape targets from shape [N] to [N,1] to match model output if needed.\n",
    "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "  model.train()\n",
    "  for i in range(epochs):\n",
    "    # convert each dataframe columns into pytorch tensors\n",
    "    users = torch.LongTensor(df_train['userId'].values)\n",
    "    items = torch.LongTensor(df_train['movieId'].values)\n",
    "    ratings = torch.FloatTensor(df_train['rating'].values)\n",
    "\n",
    "    # unsqueeze if we need to match dimensions\n",
    "    if unsqueeze:\n",
    "      ratings = ratings.unsqueeze(1)\n",
    "\n",
    "    # forward pass - predict ratings using the dot product of embeddings\n",
    "    y_hat = model(users, items)\n",
    "\n",
    "    # compute the mean squared error between predicted and actual ratings\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "\n",
    "    # clear previously stored gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # compute gradients for all model parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # updating embeddings (weights) using the computed gradients\n",
    "    # to reduce training loss by adjusting parameters\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {i+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "  test_loss(model, unsqueeze)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f764f434",
   "metadata": {},
   "source": [
    "### Testing different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bbc0eee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 12.9108\n",
      "Epoch 2/10, Loss: 4.8494\n",
      "Epoch 3/10, Loss: 2.6056\n",
      "Epoch 4/10, Loss: 3.0974\n",
      "Epoch 5/10, Loss: 0.8495\n",
      "Epoch 6/10, Loss: 1.8237\n",
      "Epoch 7/10, Loss: 2.6599\n",
      "Epoch 8/10, Loss: 2.1401\n",
      "Epoch 9/10, Loss: 1.0947\n",
      "Epoch 10/10, Loss: 0.9769\n",
      "test loss: 3.0757\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1d597358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 1.6413\n",
      "Epoch 2/15, Loss: 5.7155\n",
      "Epoch 3/15, Loss: 4.1172\n",
      "Epoch 4/15, Loss: 1.0737\n",
      "Epoch 5/15, Loss: 2.8520\n",
      "Epoch 6/15, Loss: 2.4697\n",
      "Epoch 7/15, Loss: 0.7537\n",
      "Epoch 8/15, Loss: 1.2421\n",
      "Epoch 9/15, Loss: 2.0902\n",
      "Epoch 10/15, Loss: 1.9920\n",
      "Epoch 11/15, Loss: 1.1977\n",
      "Epoch 12/15, Loss: 0.6940\n",
      "Epoch 13/15, Loss: 1.0995\n",
      "Epoch 14/15, Loss: 1.4013\n",
      "Epoch 15/15, Loss: 0.9348\n",
      "test loss: 1.4304\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=15, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9af86c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 0.6293\n",
      "Epoch 2/15, Loss: 0.5548\n",
      "Epoch 3/15, Loss: 0.5360\n",
      "Epoch 4/15, Loss: 0.5255\n",
      "Epoch 5/15, Loss: 0.5120\n",
      "Epoch 6/15, Loss: 0.4963\n",
      "Epoch 7/15, Loss: 0.4803\n",
      "Epoch 8/15, Loss: 0.4648\n",
      "Epoch 9/15, Loss: 0.4499\n",
      "Epoch 10/15, Loss: 0.4350\n",
      "Epoch 11/15, Loss: 0.4197\n",
      "Epoch 12/15, Loss: 0.4040\n",
      "Epoch 13/15, Loss: 0.3878\n",
      "Epoch 14/15, Loss: 0.3714\n",
      "Epoch 15/15, Loss: 0.3550\n",
      "test loss: 1.4070\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=15, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36594ad2",
   "metadata": {},
   "source": [
    "### Matrix Factorization with bias\n",
    "Currently we assume that all users give ratings centered around the same average and all movies have the same baseline popularity, however this is not true in real life.\n",
    "\n",
    "Some users are naturally more generous raters forexample they always rate higher and some movies are generally loved by everyone. By adding the bias we can \"normalize\" these values to increase the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "48e8525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_bias(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100):\n",
    "        super(MF_bias, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        # bias for how much a user tends to rate higher or lower than average\n",
    "        b_u = self.user_bias(u).squeeze()\n",
    "        # bias for how much an item tends to be rated higher or lower than average\n",
    "        b_v = self.item_bias(v).squeeze()\n",
    "        return (U*V).sum(1) +  b_u  + b_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "05c0b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF_bias(num_users, num_items, emb_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e0dd6fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 12.9050\n",
      "Epoch 2/10, Loss: 9.1493\n",
      "Epoch 3/10, Loss: 4.3852\n",
      "Epoch 4/10, Loss: 1.1557\n",
      "Epoch 5/10, Loss: 2.4683\n",
      "Epoch 6/10, Loss: 3.7424\n",
      "Epoch 7/10, Loss: 2.4468\n",
      "Epoch 8/10, Loss: 1.0769\n",
      "Epoch 9/10, Loss: 0.8153\n",
      "Epoch 10/10, Loss: 1.3178\n",
      "test loss: 2.8503\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.05, wd=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "71bf4040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.8930\n",
      "Epoch 2/10, Loss: 1.3249\n",
      "Epoch 3/10, Loss: 0.9351\n",
      "Epoch 4/10, Loss: 0.7448\n",
      "Epoch 5/10, Loss: 0.7222\n",
      "Epoch 6/10, Loss: 0.7773\n",
      "Epoch 7/10, Loss: 0.8231\n",
      "Epoch 8/10, Loss: 0.8222\n",
      "Epoch 9/10, Loss: 0.7818\n",
      "Epoch 10/10, Loss: 0.7278\n",
      "test loss: 1.2259\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.01, wd=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8de478b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6853\n",
      "Epoch 2/10, Loss: 0.6711\n",
      "Epoch 3/10, Loss: 0.6592\n",
      "Epoch 4/10, Loss: 0.6494\n",
      "Epoch 5/10, Loss: 0.6416\n",
      "Epoch 6/10, Loss: 0.6355\n",
      "Epoch 7/10, Loss: 0.6309\n",
      "Epoch 8/10, Loss: 0.6274\n",
      "Epoch 9/10, Loss: 0.6249\n",
      "Epoch 10/10, Loss: 0.6232\n",
      "test loss: 1.2177\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.001, wd=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592fbb76",
   "metadata": {},
   "source": [
    "### Neural Network Model\n",
    "Neural Network Models can learn nonlinear interactions between users and items not just pure similarity like using the Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fe08dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollabFNet(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100, n_hidden=10):\n",
    "        super(CollabFNet, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.lin1 = nn.Linear(emb_size*2, n_hidden)\n",
    "        self.lin2 = nn.Linear(n_hidden, 1)\n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        x = F.relu(torch.cat([U, V], dim=1))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c6d3e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CollabFNet(num_users, num_items, emb_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "172daf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 11.8611\n",
      "Epoch 2/15, Loss: 1.2061\n",
      "Epoch 3/15, Loss: 11.7211\n",
      "Epoch 4/15, Loss: 1.6822\n",
      "Epoch 5/15, Loss: 2.3878\n",
      "Epoch 6/15, Loss: 4.9893\n",
      "Epoch 7/15, Loss: 5.5557\n",
      "Epoch 8/15, Loss: 4.7141\n",
      "Epoch 9/15, Loss: 3.2336\n",
      "Epoch 10/15, Loss: 1.7677\n",
      "Epoch 11/15, Loss: 0.9652\n",
      "Epoch 12/15, Loss: 1.2551\n",
      "Epoch 13/15, Loss: 2.1266\n",
      "Epoch 14/15, Loss: 2.3708\n",
      "Epoch 15/15, Loss: 1.7475\n",
      "test loss: 1.1896\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=15, lr=0.05, wd=1e-6, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c8e4b5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.0385\n",
      "Epoch 2/10, Loss: 0.8155\n",
      "Epoch 3/10, Loss: 0.9147\n",
      "Epoch 4/10, Loss: 0.9229\n",
      "Epoch 5/10, Loss: 0.8455\n",
      "Epoch 6/10, Loss: 0.7784\n",
      "Epoch 7/10, Loss: 0.7723\n",
      "Epoch 8/10, Loss: 0.8033\n",
      "Epoch 9/10, Loss: 0.8077\n",
      "Epoch 10/10, Loss: 0.7746\n",
      "test loss: 1.0122\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.01, wd=1e-6, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73d2e6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7376\n",
      "Epoch 2/10, Loss: 0.7300\n",
      "Epoch 3/10, Loss: 0.7250\n",
      "Epoch 4/10, Loss: 0.7264\n",
      "Epoch 5/10, Loss: 0.7273\n",
      "Epoch 6/10, Loss: 0.7259\n",
      "Epoch 7/10, Loss: 0.7241\n",
      "Epoch 8/10, Loss: 0.7250\n",
      "Epoch 9/10, Loss: 0.7218\n",
      "Epoch 10/10, Loss: 0.7190\n",
      "test loss: 1.0130\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.001, wd=1e-6, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07163fa",
   "metadata": {},
   "source": [
    "### Recommend movies based on my preferences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
