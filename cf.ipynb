{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5679283f",
   "metadata": {},
   "source": [
    "# Exploring Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df0f1d",
   "metadata": {},
   "source": [
    "### By developing a movie recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df338b",
   "metadata": {},
   "source": [
    "### Movie Dataset\n",
    "Dataset source - http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8aca1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8239e5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "0            1        1     4.0   964982703\n",
       "1            1        3     4.0   964981247\n",
       "2            1        6     4.0   964982224\n",
       "3            1       47     5.0   964983815\n",
       "4            1       50     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb6656",
   "metadata": {},
   "source": [
    "### Splitting data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "453bfbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "msk = np.random.rand(len(ratings)) < 0.8\n",
    "train = ratings[msk].copy()\n",
    "val = ratings[~msk].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43fb417",
   "metadata": {},
   "source": [
    "### Encode data\n",
    "Encode data with continous user and movie ids, if train is passed to the function call, we encode df with the same encoding as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90b97e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_col(col, train_col=None):\n",
    "  # use training col if available\n",
    "  if train_col is not None:\n",
    "    uniq = train_col.unique()\n",
    "  else:\n",
    "    uniq = col.unique()\n",
    "\n",
    "  # mapping value to index\n",
    "  name2idx = {}\n",
    "  for index, val in enumerate(uniq):\n",
    "    name2idx[val] = index\n",
    "  arr = []\n",
    "  for x in col:\n",
    "    # uknown ids get encoded as -1\n",
    "    arr.append(name2idx.get(x, -1))\n",
    "  arr = np.array(arr)\n",
    "  return name2idx, arr, len(uniq) # understanding mapping, encoded array, number of unique categories\n",
    "\n",
    "def encode_data(df, train=None):\n",
    "  df = df.copy()\n",
    "  for col_name in [\"userId\", \"movieId\"]:\n",
    "    train_col = None\n",
    "    if train is not None:\n",
    "      train_col = train[col_name]\n",
    "    _, col, _ = proc_col(df[col_name], train_col)\n",
    "    df[col_name] = col\n",
    "\n",
    "    # removing the unknowns (value of -1)\n",
    "    df = df[df[col_name] >= 0]\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a0af1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = encode_data(train)\n",
    "df_val = encode_data(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c943845",
   "metadata": {},
   "source": [
    "### Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85ca8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e4b593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating embedding layer (matrix) with 10 rows and 3 columns\n",
    "# first filled with random numbers, so model can learn later during training\n",
    "embed = nn.Embedding(10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ffa62",
   "metadata": {},
   "source": [
    "### Matrix Factorization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2df4bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "  def __init__(self, num_users, num_items, emb_size=100):\n",
    "    super(MF, self).__init__()\n",
    "    # lookup table for all users\n",
    "    self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "\n",
    "    # lookup table for all items\n",
    "    self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "\n",
    "    # initialize each randomly\n",
    "    self.user_emb.weight.data.uniform_(0, 0.05)\n",
    "    self.item_emb.weight.data.uniform_(0, 0.05)\n",
    "      \n",
    "  def forward(self, u, v):\n",
    "    # replace each row with the embedding layer row\n",
    "    u = self.user_emb(u)\n",
    "    v = self.item_emb(v)\n",
    "\n",
    "    # dot product of u and v\n",
    "    return (u*v).sum(1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c02f7",
   "metadata": {},
   "source": [
    "### Training the MF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7731ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num users: 610\n",
      "num items: 8998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_users = len(df_train.userId.unique())\n",
    "num_items = len(df_train.movieId.unique())\n",
    "print(\"num users:\", num_users)\n",
    "print(\"num items:\", num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b15789bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the new matrix factorization model\n",
    "model = MF(num_users, num_items, emb_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71789eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how good the current model is without changing anything\n",
    "def test_loss(model, unsqueeze=False):\n",
    "  model.eval()\n",
    "  users = torch.LongTensor(df_val['userId'].values)\n",
    "  items = torch.LongTensor(df_val['movieId'].values)\n",
    "  ratings = torch.FloatTensor(df_val['rating'].values)\n",
    "  if unsqueeze:\n",
    "    ratings = ratings.unsqueeze(1)\n",
    "  y_hat = model(users, items)\n",
    "  loss = F.mse_loss(y_hat, ratings)\n",
    "  print(f\"test loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86518a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr: learning rate for Adam (speed of learning)\n",
    "# wd: weight decay (L2 regularization) applied by Adam to all model params (your embeddings).\n",
    "# unsqueeze: whether to reshape targets from shape [N] to [N,1] to match model output if needed.\n",
    "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "  model.train()\n",
    "  for i in range(epochs):\n",
    "    # convert each dataframe columns into pytorch tensors\n",
    "    users = torch.LongTensor(df_train['userId'].values)\n",
    "    items = torch.LongTensor(df_train['movieId'].values)\n",
    "    ratings = torch.FloatTensor(df_train['rating'].values)\n",
    "\n",
    "    # unsqueeze if we need to match dimensions\n",
    "    if unsqueeze:\n",
    "      ratings = ratings.unsqueeze(1)\n",
    "\n",
    "    # forward pass - predict ratings using the dot product of embeddings\n",
    "    y_hat = model(users, items)\n",
    "\n",
    "    # compute the mean squared error between predicted and actual ratings\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "\n",
    "    # clear previously stored gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # compute gradients for all model parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # updating embeddings (weights) using the computed gradients\n",
    "    # to reduce training loss by adjusting parameters\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {i+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "  test_loss(model, unsqueeze)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f764f434",
   "metadata": {},
   "source": [
    "### Testing different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bbc0eee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 12.9140\n",
      "Epoch 2/10, Loss: 12.5060\n",
      "Epoch 3/10, Loss: 11.9756\n",
      "Epoch 4/10, Loss: 11.3311\n",
      "Epoch 5/10, Loss: 10.5820\n",
      "Epoch 6/10, Loss: 9.7397\n",
      "Epoch 7/10, Loss: 8.8184\n",
      "Epoch 8/10, Loss: 7.8356\n",
      "Epoch 9/10, Loss: 6.8129\n",
      "Epoch 10/10, Loss: 5.7758\n",
      "test loss: 4.7717\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d597358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 4.7544\n",
      "Epoch 2/20, Loss: 3.8178\n",
      "Epoch 3/20, Loss: 2.9628\n",
      "Epoch 4/20, Loss: 2.2228\n",
      "Epoch 5/20, Loss: 1.6284\n",
      "Epoch 6/20, Loss: 1.2018\n",
      "Epoch 7/20, Loss: 0.9494\n",
      "Epoch 8/20, Loss: 0.8546\n",
      "Epoch 9/20, Loss: 0.8774\n",
      "Epoch 10/20, Loss: 0.9614\n",
      "Epoch 11/20, Loss: 1.0499\n",
      "Epoch 12/20, Loss: 1.1023\n",
      "Epoch 13/20, Loss: 1.1020\n",
      "Epoch 14/20, Loss: 1.0535\n",
      "Epoch 15/20, Loss: 0.9746\n",
      "Epoch 16/20, Loss: 0.8869\n",
      "Epoch 17/20, Loss: 0.8087\n",
      "Epoch 18/20, Loss: 0.7516\n",
      "Epoch 19/20, Loss: 0.7196\n",
      "Epoch 20/20, Loss: 0.7103\n",
      "test loss: 1.5562\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=20, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9af86c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.7169\n",
      "Epoch 2/20, Loss: 10.4183\n",
      "Epoch 3/20, Loss: 1.1558\n",
      "Epoch 4/20, Loss: 2.2212\n",
      "Epoch 5/20, Loss: 4.5572\n",
      "Epoch 6/20, Loss: 5.2357\n",
      "Epoch 7/20, Loss: 5.0751\n",
      "Epoch 8/20, Loss: 4.2550\n",
      "Epoch 9/20, Loss: 2.9255\n",
      "Epoch 10/20, Loss: 1.7810\n",
      "Epoch 11/20, Loss: 1.5063\n",
      "Epoch 12/20, Loss: 1.8308\n",
      "Epoch 13/20, Loss: 1.9978\n",
      "Epoch 14/20, Loss: 1.8274\n",
      "Epoch 15/20, Loss: 1.5248\n",
      "Epoch 16/20, Loss: 1.2991\n",
      "Epoch 17/20, Loss: 1.2296\n",
      "Epoch 18/20, Loss: 1.2934\n",
      "Epoch 19/20, Loss: 1.3910\n",
      "Epoch 20/20, Loss: 1.3314\n",
      "test loss: 2.0961\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=20, lr=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
